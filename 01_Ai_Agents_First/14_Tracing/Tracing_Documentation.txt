  Tracing_Documentation

  https://openai.github.io/openai-agents-python/voice/tracing/

  Just like the way agents are traced, voice pipelines are also automatically traced.

  You can read the tracing doc above for basic tracing information, but you can additionally configure tracing of a pipeline via VoicePipelineConfig.

  Pipeline Config
  VoicePipelineConfig dataclass

  Configuration for a VoicePipeline.
  Source code in src/agents/voice/pipeline_config.py

  model_provider class-attribute instance-attribute

  model_provider: VoiceModelProvider = field(
    default_factory=OpenAIVoiceModelProvider
  )

  The voice model provider to use for the pipeline. Defaults to OpenAI.
  tracing_disabled class-attribute instance-attribute

  tracing_disabled: bool = False

  Whether to disable tracing of the pipeline. Defaults to False.
  trace_include_sensitive_data class-attribute instance-attribute

  trace_include_sensitive_data: bool = True

  Whether to include sensitive data in traces. Defaults to True. This is specifically for the voice pipeline, and not for anything that goes on inside your Workflow.
  trace_include_sensitive_audio_data class-attribute instance-attribute

  trace_include_sensitive_audio_data: bool = True

  Whether to include audio data in traces. Defaults to True.
  workflow_name class-attribute instance-attribute

  workflow_name: str = 'Voice Agent'

  The name of the workflow to use for tracing. Defaults to Voice Agent.
  group_id class-attribute instance-attribute

  group_id: str = field(default_factory=gen_group_id)

  A grouping identifier to use for tracing, to link multiple traces from the same conversation or process. If not provided, we will create a random group ID.
  trace_metadata class-attribute instance-attribute

  trace_metadata: dict[str, Any] | None = None

  An optional dictionary of additional metadata to include with the trace.
  stt_settings class-attribute instance-attribute

  stt_settings: STTModelSettings = field(
    default_factory=STTModelSettings
  )

  The settings to use for the STT model.
  tts_settings class-attribute instance-attribute

  tts_settings: TTSModelSettings = field(
    default_factory=TTSModelSettings
  )

  The settings to use for the TTS model.



  Key tracing related fields are:

    tracing_disabled: controls whether tracing is disabled. By default, tracing is enabled.
    trace_include_sensitive_data: controls whether traces include potentially sensitive data, like audio transcripts. This is specifically for the voice pipeline, and not for anything that goes on inside your Workflow.
    trace_include_sensitive_audio_data: controls whether traces include audio data.
    workflow_name: The name of the trace workflow.
    group_id: The group_id of the trace, which lets you link multiple traces.
    trace_metadata: Additional metadata to include with the trace.

    Model

  TTSVoice module-attribute

  TTSVoice = Literal[
    "alloy",
    "ash",
    "coral",
    "echo",
    "fable",
    "onyx",
    "nova",
    "sage",
    "shimmer",
  ]

  Exportable type for the TTSModelSettings voice enum
  TTSModelSettings dataclass

  Settings for a TTS model.
  Source code in src/agents/voice/model.py

  voice class-attribute instance-attribute

  voice: TTSVoice | None = None

  The voice to use for the TTS model. If not provided, the default voice for the respective model will be used.
  buffer_size class-attribute instance-attribute

  buffer_size: int = 120

  The minimal size of the chunks of audio data that are being streamed out.
  dtype class-attribute instance-attribute

  dtype: DTypeLike = int16

  The data type for the audio data to be returned in.
  transform_data class-attribute instance-attribute

  transform_data: (
    Callable[
        [NDArray[int16 | float32]], NDArray[int16 | float32]
    ]
    | None
  ) = None

  A function to transform the data from the TTS model. This is useful if you want the resulting audio stream to have the data in a specific shape already.
  instructions class-attribute instance-attribute

  instructions: str = "You will receive partial sentences. Do not complete the sentence just read out the text."

  The instructions to use for the TTS model. This is useful if you want to control the tone of the audio output.
  text_splitter class-attribute instance-attribute

  text_splitter: Callable[[str], tuple[str, str]] = (
    get_sentence_based_splitter()
  )

  A function to split the text into chunks. This is useful if you want to split the text into chunks before sending it to the TTS model rather than waiting for the whole text to be processed.
  speed class-attribute instance-attribute

  speed: float | None = None

  The speed with which the TTS model will read the text. Between 0.25 and 4.0.
  TTSModel

  Bases: ABC

  A text-to-speech model that can convert text into audio output.
  Source code in src/agents/voice/model.py

  model_name abstractmethod property

  model_name: str

  The name of the TTS model.
  run abstractmethod

  run(
    text: str, settings: TTSModelSettings
  ) -> AsyncIterator[bytes]

  Given a text string, produces a stream of audio bytes, in PCM format.

  Parameters:
  Name 	Type 	Description 	Default
  text 	str 	

  The text to convert to audio.
	required

  Returns:
  Type 	Description
  AsyncIterator[bytes] 	

  An async iterator of audio bytes, in PCM format.
  Source code in src/agents/voice/model.py

  StreamedTranscriptionSession

  Bases: ABC

  A streamed transcription of audio input.
  Source code in src/agents/voice/model.py

  transcribe_turns abstractmethod

  transcribe_turns() -> AsyncIterator[str]

  Yields a stream of text transcriptions. Each transcription is a turn in the conversation.

  This method is expected to return only after close() is called.
  Source code in src/agents/voice/model.py

  close abstractmethod async

  close() -> None

  Closes the session.
  Source code in src/agents/voice/model.py

  STTModelSettings dataclass

  Settings for a speech-to-text model.
  Source code in src/agents/voice/model.py

  prompt class-attribute instance-attribute

  prompt: str | None = None

  Instructions for the model to follow.
  language class-attribute instance-attribute

  language: str | None = None

  The language of the audio input.
  temperature class-attribute instance-attribute

  temperature: float | None = None

  The temperature of the model.
  turn_detection class-attribute instance-attribute

  turn_detection: dict[str, Any] | None = None

  The turn detection settings for the model when using streamed audio input.
  STTModel

  Bases: ABC

  A speech-to-text model that can convert audio input into text.
  Source code in src/agents/voice/model.py

  model_name abstractmethod property

  model_name: str

  The name of the STT model.
  transcribe abstractmethod async

  transcribe(
    input: AudioInput,
    settings: STTModelSettings,
    trace_include_sensitive_data: bool,
    trace_include_sensitive_audio_data: bool,
  ) -> str

  Given an audio input, produces a text transcription.

  Parameters:
  Name 	Type 	Description 	Default
  input 	AudioInput 	

  The audio input to transcribe.
	required
  settings 	STTModelSettings 	

  The settings to use for the transcription.
	required
  trace_include_sensitive_data 	bool 	

  Whether to include sensitive data in traces.
	required
  trace_include_sensitive_audio_data 	bool 	

  Whether to include sensitive audio data in traces.
	required

  Returns:
  Type 	Description
  str

  The text transcription of the audio input.
  Source code in src/agents/voice/model.py

  create_session abstractmethod async

  create_session(
    input: StreamedAudioInput,
    settings: STTModelSettings,
    trace_include_sensitive_data: bool,
    trace_include_sensitive_audio_data: bool,
  ) -> StreamedTranscriptionSession

  Creates a new transcription session, which you can push audio to, and receive a stream of text transcriptions.

  Parameters:
  Name 	Type 	Description 	Default
  input 	StreamedAudioInput 	

  The audio input to transcribe.
	required
  settings 	STTModelSettings 	

  The settings to use for the transcription.
	required
  trace_include_sensitive_data 	bool 	

  Whether to include sensitive data in traces.
	required
  trace_include_sensitive_audio_data 	bool 	

  Whether to include sensitive audio data in traces.
	required

  Returns:
  Type 	Description
  StreamedTranscriptionSession 	

  A new transcription session.
  Source code in src/agents/voice/model.py

  VoiceModelProvider

  Bases: ABC

  The base interface for a voice model provider.

  A model provider is responsible for creating speech-to-text and text-to-speech models, given a name.
  Source code in src/agents/voice/model.py

  get_stt_model abstractmethod

  get_stt_model(model_name: str | None) -> STTModel

  Get a speech-to-text model by name.

  Parameters:
  Name 	Type 	Description 	Default
  model_name 	str | None 	

  The name of the model to get.
	required

  Returns:
  Type 	Description
  STTModel

  The speech-to-text model.
  Source code in src/agents/voice/model.py

  get_tts_model abstractmethod

  get_tts_model(model_name: str | None) -> TTSModel

  Get a text-to-speech model by name.
  Source code in src/agents/voice/model.py
