{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10fd3e0",
   "metadata": {},
   "source": [
    "    ### Open AI Agents SSDK Hooks   /     اوپنائی ایجنٹس ایس ڈی کے ہکس\n",
    "لائف سائیکل\n",
    "\n",
    "    # Lifecycle     /   لائف سائیکل\n",
    "\n",
    "RunHooks module-attribute   /    ہکس ماڈیول وصف چلائیں۔\n",
    "\n",
    "Run hooks when using Agent. /   ایجنٹ کا استعمال کرتے وقت ہکس چلائیں۔\n",
    "\n",
    "AgentHooks module-attribute   /    ایجنٹ ہکس ماڈیول وصف\n",
    "\n",
    "Agent hooks for Agents.      /    ایجنٹوں کے لیے ایجنٹ ہکس\n",
    "\n",
    "RunHooksBase                /    رن ہکس بیس\n",
    "\n",
    "Bases: Generic[TContext, TAgent] / بنیادیں: عام ٹی سیاق و سباق، ٹی ایجنٹ\n",
    "\n",
    "A class that receives callbacks on various lifecycle events in an agent run. Subclass and override the methods you need.\n",
    "\n",
    "ایک ایسی کلاس جو ایجنٹ کے دوران زندگی کے مختلف واقعات پر کال بیکس وصول کرتی ہے۔ ذیلی کلاس اور ان طریقوں کو اوور رائڈ کریں جن کی آپ کو ضرورت ہے۔\n",
    "\n",
    "Called just before invoking the LLM for this agent. /   اس ایجنٹ کے لیے ایل ایل ایم کو طلب کرنے سے پہلے کال کی گئی۔\n",
    "\n",
    "Called immediately after the LLM call returns for this agent. / اس ایجنٹ کے لیے ایل ایل ایم کال واپس آنے کے فوراً بعد کال کی جاتی ہے۔\n",
    "\n",
    "Called before the agent is invoked. Called each time the current agent changes.\n",
    "\n",
    "ایجنٹ کو طلب کرنے سے پہلے کال کی جاتی ہے۔ ہر بار جب موجودہ ایجنٹ تبدیل ہوتا ہے کال کی جاتی ہے۔\n",
    "\n",
    "Called when the agent produces a final output.  /   اس وقت کال کی جاتی ہے جب ایجنٹ حتمی آؤٹ پٹ تیار کرتا ہے۔\n",
    "\n",
    "Called when a handoff occurs.                  /    جب ہینڈ آف ہوتا ہے تو اسے کال کیا جاتا ہے۔\n",
    "\n",
    "Called concurrently with tool invocation.     /     ٹول انووکیشن کے ساتھ بیک وقت بلایا جاتا ہے۔\n",
    "\n",
    "Called after a tool is invoked.              /      کسی آلے کو طلب کرنے کے بعد کال کی جاتی ہے۔\n",
    "\n",
    "AgentHooksBase                              /       ایجنٹ ہکس بیس\n",
    "\n",
    "Bases: Generic[TContext, TAgent]            /       بنیادیں: عام ٹی سیاق و سباق، ٹی ایجنٹ\n",
    "\n",
    "A class that receives callbacks on various lifecycle events for a specific agent. You can set this on agent.hooks to receive events for that specific agent.\n",
    "\n",
    "ایک کلاس جو ایک مخصوص ایجنٹ کے لیے زندگی کے مختلف واقعات پر کال بیکس وصول کرتی ہے۔ آپ اسے ایجنٹ پر سیٹ کر سکتے ہیں۔ اس مخصوص ایجنٹ کے لیے واقعات وصول کرنے کے لیے ہکس۔\n",
    "\n",
    "Subclass and override the methods you need. /       ذیلی کلاس اور ان طریقوں کو اوور رائڈ کریں جن کی آپ کو ضرورت ہے۔\n",
    "\n",
    "Called before the agent is invoked. Called each time the running agent is changed to this agent.\n",
    "\n",
    "ایجنٹ کو طلب کرنے سے پہلے کال کی جاتی ہے۔ ہر بار جب چلانے والے ایجنٹ کو اس ایجنٹ میں تبدیل کیا جاتا ہے تو کال کی جاتی ہے۔\n",
    "\n",
    "Called when the agent produces a final output.  /   اس وقت کال کی جاتی ہے جب ایجنٹ حتمی آؤٹ پٹ تیار کرتا ہے۔\n",
    "\n",
    "Called when the agent is being handed off to. The source is the agent that is handing off to this agent.\n",
    "\n",
    "جب ایجنٹ کے حوالے کیا جا رہا ہو تو کال کی جاتی ہے۔ ذریعہ وہ ایجنٹ ہے جو اس ایجنٹ کو دے رہا ہے۔\n",
    "\n",
    "Called concurrently with tool invocation.      /    ٹول انووکیشن کے ساتھ بیک وقت بلایا جاتا ہے۔\n",
    "\n",
    "Called after a tool is invoked.               /     کسی آلے کو طلب کرنے کے بعد کال کی جاتی ہے۔\n",
    "\n",
    "Called immediately before the agent issues an LLM call. / ایجنٹ کے ایل ایل ایم کال جاری کرنے سے پہلے فوراً کال کی جاتی ہے۔\n",
    "\n",
    "Called immediately after the agent receives the LLM response. / ایجنٹ کوایل ایل ایم جواب موصول ہونے کےفوراًبعدکال کی جاتی ہے۔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae700e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RunHooks = RunHooksBase[TContext, Agent]\n",
    "\n",
    "AgentHooks = AgentHooksBase[TContext, Agent]\n",
    "\n",
    "on_llm_start async\n",
    "\n",
    "on_llm_start(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    system_prompt: Optional[str],\n",
    "    input_items: list[TResponseInputItem],\n",
    ") -> None\n",
    "\n",
    "on_llm_end async\n",
    "\n",
    "on_llm_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    response: ModelResponse,\n",
    ") -> None\n",
    "\n",
    "on_agent_start async\n",
    "\n",
    "on_agent_start(\n",
    "    context: RunContextWrapper[TContext], agent: TAgent\n",
    ") -> None\n",
    "\n",
    "on_agent_end async\n",
    "\n",
    "on_agent_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    output: Any,\n",
    ") -> None\n",
    "\n",
    "on_handoff asyn\n",
    "\n",
    "on_handoff(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    from_agent: TAgent,\n",
    "    to_agent: TAgent,\n",
    ") -> None\n",
    "\n",
    "on_tool_start async\n",
    "\n",
    "on_tool_start(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    tool: Tool,\n",
    ") -> None\n",
    "\n",
    "on_tool_end async\n",
    "\n",
    "on_tool_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    tool: Tool,\n",
    "    result: str,\n",
    ") -> None\n",
    "\n",
    "on_start async\n",
    "\n",
    "on_start(\n",
    "    context: RunContextWrapper[TContext], agent: TAgent\n",
    ") -> None\n",
    "\n",
    "on_end async\n",
    "\n",
    "on_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    output: Any,\n",
    ") -> None\n",
    "\n",
    "on_handoff async\n",
    "\n",
    "on_handoff(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    source: TAgent,\n",
    ") -> None\n",
    "\n",
    "on_tool_start async\n",
    "\n",
    "on_tool_start(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    tool: Tool,\n",
    ") -> None\n",
    "\n",
    "on_tool_end async\n",
    "\n",
    "on_tool_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: TAgent,\n",
    "    tool: Tool,\n",
    "    result: str,\n",
    ") -> None\n",
    "\n",
    "on_llm_start async\n",
    "\n",
    "on_llm_start(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    system_prompt: Optional[str],\n",
    "    input_items: list[TResponseInputItem],\n",
    ") -> None\n",
    "\n",
    "on_llm_end async\n",
    "\n",
    "on_llm_end(\n",
    "    context: RunContextWrapper[TContext],\n",
    "    agent: Agent[TContext],\n",
    "    response: ModelResponse,\n",
    ") -> None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131af8e",
   "metadata": {},
   "source": [
    "Running agents\n",
    "\n",
    "You can run agents via the Runner class. You have 3 options:\n",
    "\n",
    "1. Runner.run(), which runs async and returns a RunResult.\n",
    "\n",
    "2. Runner.run_sync(), which is a sync method and just runs .run() under the hood.\n",
    "\n",
    "3. Runner.run_streamed(), which runs async and returns a RunResultStreaming. It calls the LLM in streaming mode, and streams \n",
    "   those events to you as they are received.\n",
    "\n",
    "چلانے والے ایجنٹس\n",
    "\n",
    "آپ رنر کلاس کے ذریعے ایجنٹ چلا سکتے ہیں۔ آپ کے پاس 3 اختیارات ہیں:\n",
    "\n",
    "1. Runner.run()، جو async چلاتا ہے اور رن کا نتیجہ لوٹاتا ہے۔\n",
    "\n",
    "2. Runner.run_sync()، جو ایک مطابقت پذیری کا طریقہ ہے اور صرف .run() کو ہڈ کے نیچے چلاتا ہے۔\n",
    "\n",
    "3. Runner.run_streamed()، جو async چلاتا ہے اور رن رزلٹ سٹریمنگ لوٹاتا ہے۔ یہ LLM کو سٹریمنگ موڈ اور اسٹریمز میں کال کرتا ہے۔ \n",
    "آپ کو وہ واقعات جیسے موصول ہوئے ہیں۔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
    "\n",
    "    result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
    "    print(result.final_output)\n",
    "    # Code within the code,\n",
    "    # Functions calling themselves,\n",
    "    # Infinite loop's dance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c73b40e",
   "metadata": {},
   "source": [
    "Streaming\n",
    "\n",
    "Streaming allows you to additionally receive streaming events as the LLM runs. Once the stream is done, the RunResultStreaming will contain the complete information about the run, including all the new outputs produced. You can call .stream_events() for the streaming events. Read more in the streaming guide.\n",
    "\n",
    "Run config\n",
    "\n",
    "The run_config parameter lets you configure some global settings for the agent run:\n",
    "\n",
    "* model: Allows setting a global LLM model to use, irrespective of what model each Agent has.\n",
    "\n",
    "* model_provider: A model provider for looking up model names, which defaults to OpenAI.\n",
    "\n",
    "* model_settings: Overrides agent-specific settings. For example, you can set a global temperature or top_p.\n",
    "\n",
    "* input_guardrails, output_guardrails: A list of input or output guardrails to include on all runs.\n",
    "* handoff_input_filter: A global input filter to apply to all handoffs, if the handoff doesn't already have one. The input \n",
    "  filter allows you to edit the inputs that are sent to the new agent. See the documentation in Handoff.input_filter for more details.\n",
    "\n",
    "* tracing_disabled: Allows you to disable tracing for the entire run.\n",
    "\n",
    "* trace_include_sensitive_data: Configures whether traces will include potentially sensitive data, such as LLM and tool call \n",
    "  inputs/outputs.\n",
    "\n",
    "* workflow_name, trace_id, group_id: Sets the tracing workflow name, trace ID and trace group ID for the run. We recommend at \n",
    "  least setting workflow_name. The group ID is an optional field that lets you link traces across multiple runs.\n",
    "\n",
    "* trace_metadata: Metadata to include on all traces.\n",
    "\n",
    "Conversations/chat threads\n",
    "\n",
    "Calling any of the run methods can result in one or more agents running (and hence one or more LLM calls), but it represents a single logical turn in a chat conversation. For example:\n",
    "\n",
    "1. User turn: user enter text\n",
    "\n",
    "2. Runner run: first agent calls LLM, runs tools, does a handoff to a second agent, second agent runs more tools, and then \n",
    "   produces an output.\n",
    "\n",
    "At the end of the agent run, you can choose what to show to the user. For example, you might show the user every new item generated by the agents, or just the final output. Either way, the user might then ask a followup question, in which case you can call the run method again.\n",
    "\n",
    "Manual conversation management\n",
    "\n",
    "You can manually manage conversation history using the RunResultBase.to_input_list() method to get the inputs for the next turn:\n",
    "\n",
    "سلسلہ بندی\n",
    "\n",
    "سٹریمنگ آپ کو LLM کے چلنے کے ساتھ ساتھ سٹریمنگ ایونٹس حاصل کرنے کی بھی اجازت دیتی ہے۔ ایک بار اسٹریم مکمل ہونے کے بعد، رن رزلٹ اسٹریمنگ رن کے بارے میں مکمل معلومات پر مشتمل ہوگی، بشمول تمام نئے آؤٹ پٹ تیار کیے گئے ہیں۔ آپ کال کر سکتے ہیں۔ اسٹریمنگ ایونٹس کے لیے _ ایونٹس () کو اسٹریم کریں۔ اسٹریمنگ گائیڈ میں مزید پڑھیں۔\n",
    "\n",
    "تشکیل چلائیں۔\n",
    "\n",
    "run _ config پیرامیٹر آپ کو ایجنٹ رن کے لیے کچھ عالمی ترتیبات کو ترتیب دینے دیتا ہے:\n",
    "\n",
    "* ماڈل: ایک عالمی ایل ایل ایم ماڈل کو استعمال کرنے کی اجازت دیتا ہے، قطع نظر اس کے کہ ہر ایجنٹ کے پاس کون سا ماڈل ہے۔\n",
    "\n",
    "* model_provider: ماڈل کے نام تلاش کرنے کے لیے ایک ماڈل فراہم کنندہ، جو OpenAI سے پہلے سے طے شدہ ہے۔\n",
    "\n",
    "* ماڈل_سیٹنگز: ایجنٹ کی مخصوص ترتیبات کو اوور رائیڈ کرتا ہے۔ مثال کے طور پر، آپ عالمی درجہ حرارت یا top_p سیٹ کر سکتے ہیں۔\n",
    "\n",
    "* input_guardrails، output_guardrails: تمام رنز پر شامل کرنے کے لیے ان پٹ یا آؤٹ پٹ گارڈریلز کی فہرست۔\n",
    "* ہینڈ آف_ان پٹ_فلٹر: تمام ہینڈ آف پر لاگو کرنے کے لیے ایک عالمی ان پٹ فلٹر، اگر ہینڈ آف میں پہلے سے کوئی نہیں ہے۔ ان پٹ \n",
    "فلٹر آپ کو ان پٹس میں ترمیم کرنے کی اجازت دیتا ہے جو نئے ایجنٹ کو بھیجے جاتے ہیں۔ مزید تفصیلات کے لیے Handoff.input_filter میں دستاویزات دیکھیں۔\n",
    "\n",
    "* tracing_disabled: آپ کو پورے رن کے لیے ٹریسنگ کو غیر فعال کرنے کی اجازت دیتا ہے۔\n",
    "\n",
    "* trace_include_sensitive_data: کنفیگر کرتا ہے کہ آیا نشانات میں ممکنہ طور پر حساس ڈیٹا شامل ہوگا، جیسے LLM اور ٹول کال \n",
    "ان پٹ/آؤٹ پٹس۔\n",
    "\n",
    "* workflow_name، trace_id، group_id: رن کے لیے ٹریسنگ ورک فلو کا نام، ٹریس ID اور ٹریس گروپ ID سیٹ کرتا ہے۔ ہم پر سفارش کرتے ہیں \n",
    "کم از کم ترتیب workflow_name. گروپ ID ایک اختیاری فیلڈ ہے جو آپ کو متعدد رنز کے نشانات کو لنک کرنے دیتا ہے۔\n",
    "\n",
    "* ٹریس_میٹا ڈیٹا: تمام نشانات پر شامل کرنے کے لیے میٹا ڈیٹا۔\n",
    "\n",
    "گفتگو/چیٹ تھریڈز\n",
    "\n",
    "رن طریقوں میں سے کسی کو کال کرنے کے نتیجے میں ایک یا زیادہ ایجنٹ چل سکتے ہیں (اور اس وجہ سے ایک یا زیادہ ایل ایل ایم کالز)، لیکن یہ بات چیت میں ایک ہی منطقی موڑ کی نمائندگی کرتا ہے۔ مثال کے طور پر:\n",
    "\n",
    "1. صارف کی باری: صارف متن درج کریں۔\n",
    "\n",
    "2. رنر رن: پہلا ایجنٹ ایل ایل ایم کو کال کرتا ہے، ٹولز چلاتا ہے، دوسرے ایجنٹ کو ہینڈ آف کرتا ہے، دوسرا ایجنٹ مزید ٹولز چلاتا ہے، اور پھر \n",
    "ایک آؤٹ پٹ پیدا کرتا ہے۔\n",
    "\n",
    "ایجنٹ کی دوڑ کے اختتام پر، آپ منتخب کر سکتے ہیں کہ صارف کو کیا دکھانا ہے۔ مثال کے طور پر، آپ صارف کو ایجنٹوں کی طرف سے تیار کردہ ہر نئی چیز، یا صرف حتمی آؤٹ پٹ دکھا سکتے ہیں۔ کسی بھی طرح سے، صارف پھر فالو اپ سوال پوچھ سکتا ہے، ایسی صورت میں آپ رن میتھڈ کو دوبارہ کال کر سکتے ہیں۔\n",
    "\n",
    "دستی گفتگو کا انتظام\n",
    "\n",
    "آپ RunResultBase.to_input_list() طریقہ استعمال کرکے دستی طور پر گفتگو کی سرگزشت کا نظم کر سکتے ہیں تاکہ اگلے موڑ کے لیے معلومات حاصل کی جا سکیں:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9ccf9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"Reply very concisely.\")\n",
    "\n",
    "    thread_id = \"thread_123\"  # Example thread ID\n",
    "    with trace(workflow_name=\"Conversation\", group_id=thread_id):\n",
    "        # First turn\n",
    "        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\")\n",
    "        print(result.final_output)\n",
    "        # San Francisco\n",
    "\n",
    "        # Second turn\n",
    "        new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What state is it in?\"}]\n",
    "        result = await Runner.run(agent, new_input)\n",
    "        print(result.final_output)\n",
    "        # California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57231e86",
   "metadata": {},
   "source": [
    "Automatic conversation management with Sessions\n",
    "\n",
    "For a simpler approach, you can use Sessions to automatically handle conversation history without manually calling .to_input_list():\n",
    "\n",
    "سیشن کے ساتھ بات چیت کا خودکار انتظام\n",
    "\n",
    "ایک آسان طریقہ کے لیے، آپ .to_input_list() کو دستی طور پر کال کیے بغیر گفتگو کی سرگزشت کو خود بخود ہینڈل کرنے کے لیے سیشنز کا استعمال کر سکتے ہیں:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc295d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, SQLiteSession\n",
    "\n",
    "async def main():\n",
    "    agent = Agent(name=\"Assistant\", instructions=\"Reply very concisely.\")\n",
    "\n",
    "    # Create session instance\n",
    "    session = SQLiteSession(\"conversation_123\")\n",
    "\n",
    "    thread_id = \"thread_123\"  # Example thread ID\n",
    "    with trace(workflow_name=\"Conversation\", group_id=thread_id):\n",
    "        # First turn\n",
    "        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\", session=session)\n",
    "        print(result.final_output)\n",
    "        # San Francisco\n",
    "\n",
    "        # Second turn - agent automatically remembers previous context\n",
    "        result = await Runner.run(agent, \"What state is it in?\", session=session)\n",
    "        print(result.final_output)\n",
    "        # California"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f3a32f",
   "metadata": {},
   "source": [
    "Sessions automatically:\n",
    "\n",
    "* Retrieves conversation history before each run\n",
    "\n",
    "* Stores new messages after each run\n",
    "\n",
    "* Maintains separate conversations for different session IDs\n",
    "\n",
    "See the Sessions documentation for more details.\n",
    "\n",
    "Long running agents & human-in-the-loop\n",
    "\n",
    "You can use the Agents SDK Temporal integration to run durable, long-running workflows, including human-in-the-loop tasks. View a demo of Temporal and the Agents SDK working in action to complete long-running tasks in this video, and view docs here.\n",
    "\n",
    "Exceptions\n",
    "\n",
    "The SDK raises exceptions in certain cases. The full list is in agents.exceptions. As an overview:\n",
    "\n",
    "*. AgentsException: This is the base class for all exceptions raised within the SDK. It serves as a generic type from which all other specific exceptions are derived.\n",
    "\n",
    "* MaxTurnsExceeded: This exception is raised when the agent's run exceeds the max_turns limit passed to the Runner.run, Runner.\n",
    "  run_sync, or Runner.run_streamed methods. It indicates that the agent could not complete its task within the specified number of interaction turns.\n",
    "\n",
    "* ModelBehaviorError: This exception occurs when the underlying model (LLM) produces unexpected or invalid outputs. This can \n",
    "  include:\n",
    "\n",
    "* Malformed JSON: When the model provides a malformed JSON structure for tool calls or in its direct output, especially if a \n",
    "  specific output_type is defined.\n",
    "\n",
    "* Unexpected tool-related failures: When the model fails to use tools in an expected manner\n",
    "\n",
    "* UserError: This exception is raised when you (the person writing code using the SDK) make an error while using the SDK. This \n",
    "  typically results from incorrect code implementation, invalid configuration, or misuse of the SDK's API.\n",
    "\n",
    "* InputGuardrailTripwireTriggered, OutputGuardrailTripwireTriggered: This exception is raised when the conditions of an input \n",
    "  guardrail or output guardrail are met, respectively. Input guardrails check incoming messages before processing, while output guardrails check the agent's final response before delivery.\n",
    "\n",
    "سیشنز خود بخود:\n",
    "\n",
    "* ہر رن سے پہلے گفتگو کی تاریخ بازیافت کرتا ہے۔\n",
    "\n",
    "* ہر رن کے بعد نئے پیغامات کو اسٹور کرتا ہے۔\n",
    "\n",
    "* مختلف سیشن آئی ڈیز کے لیے الگ بات چیت کو برقرار رکھتا ہے۔\n",
    "\n",
    "مزید تفصیلات کے لیے سیشن کی دستاویزات دیکھیں۔\n",
    "\n",
    "طویل عرصے سے چلنے والے ایجنٹ اور ہیومن ان دی لوپ\n",
    "\n",
    "آپ پائیدار، طویل عرصے سے چلنے والے ورک فلو کو چلانے کے لیے ایجنٹس SDK ٹیمپورل انضمام کا استعمال کر سکتے ہیں، بشمول ہیومن ان دی لوپ ٹاسکس۔ اس ویڈیو میں طویل عرصے سے چلنے والے کاموں کو مکمل کرنے کے لیے ایکشن میں کام کرنے والے Temporal اور Agents SDK کا ایک ڈیمو دیکھیں، اور یہاں دستاویزات دیکھیں۔\n",
    "\n",
    "مستثنیات\n",
    "\n",
    "SDK بعض صورتوں میں مستثنیات کو بڑھاتا ہے۔ پوری فہرست agents.exceptions میں ہے۔ ایک جائزہ کے طور پر:\n",
    "\n",
    "* ایجنٹس استثنیٰ: یہ SDK کے اندر اٹھائے گئے تمام مستثنیات کے لیے بنیادی کلاس ہے۔ یہ ایک عام قسم کے طور پر کام کرتا ہے جس سے دیگر تمام مخصوص مستثنیات اخذ کیے گئے ہیں۔\n",
    "\n",
    "* MaxTurnsExceeded: یہ استثنا اس وقت اٹھایا جاتا ہے جب ایجنٹ کا رن Runner.run، Runner کو دی گئی max_turns کی حد سے تجاوز کر جاتا ہے۔ \n",
    "run_sync، یا Runner.run_streamed طریقے۔ یہ اشارہ کرتا ہے کہ ایجنٹ تعامل کے موڑ کی مخصوص تعداد کے اندر اپنا کام مکمل نہیں کر سکا۔\n",
    "\n",
    "* Model Behavior Error: یہ استثنا اس وقت ہوتا ہے جب بنیادی ماڈل (LLM) غیر متوقع یا غلط آؤٹ پٹ پیدا کرتا ہے۔ یہ کر سکتے ہیں \n",
    "شامل ہیں:\n",
    "\n",
    "* خراب JSON: جب ماڈل ٹول کالز کے لیے یا اس کے براہ راست آؤٹ پٹ میں ایک خراب JSON ڈھانچہ فراہم کرتا ہے، خاص طور پر اگر \n",
    "مخصوص output_type کی وضاحت کی گئی ہے۔\n",
    "\n",
    "* ٹول سے متعلق غیر متوقع ناکامیاں: جب ماڈل ٹولز کو متوقع انداز میں استعمال کرنے میں ناکام ہوجاتا ہے۔\n",
    "\n",
    "* صارف کی خرابی: یہ استثنا اس وقت اٹھایا جاتا ہے جب آپ (SDK کا استعمال کرتے ہوئے کوڈ لکھنے والا شخص) SDK استعمال کرتے ہوئے غلطی کرتے ہیں۔ یہ \n",
    "عام طور پر غلط کوڈ کے نفاذ، غلط کنفیگریشن، یا SDK کے API کے غلط استعمال کا نتیجہ ہوتا ہے۔\n",
    "\n",
    "* InputGuardrailTripwireTriggered، OutputGuardrailTripwireTriggered: یہ استثنا اس وقت اٹھایا جاتا ہے جب کسی ان پٹ کی شرائط \n",
    "بالترتیب guardrail یا آؤٹ پٹ guardrail ملتے ہیں۔ ان پٹ گارڈریلز پروسیسنگ سے پہلے آنے والے پیغامات کو چیک کرتے ہیں، جبکہ آؤٹ پٹ گارڈریلز ڈیلیوری سے پہلے ایجنٹ کے حتمی جواب کو چیک کرتے ہیں۔"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
